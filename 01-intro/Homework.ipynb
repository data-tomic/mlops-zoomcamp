{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11614de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4942396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcae7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29881abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Binary output can mess up your terminal. Use \"--output -\" to tell \r\n",
      "Warning: curl to output it to your terminal anyway, or consider \"--output \r\n",
      "Warning: <FILE>\" to save to a file.\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b569a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 42.3 MB 29.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d8bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         14.30                   2.5         0.00  \n",
       "1                    1.0         16.90                   2.5         0.00  \n",
       "2                    1.0         34.90                   2.5         0.00  \n",
       "3                    1.0         20.85                   0.0         1.25  \n",
       "4                    1.0         19.68                   2.5         0.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008685a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3066766, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b426467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527c8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b59481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_minutes'] = df['duration'].dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63d2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev_duration = df['duration'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd59dad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Timedelta.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mСтандартное отклонение продолжительности поездок в январе: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_dev_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m минут\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Timedelta.__format__"
     ]
    }
   ],
   "source": [
    "print(f\"\\nСтандартное отклонение продолжительности поездок в январе: {std_dev_duration:.2f} минут\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0520f7c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Timedelta.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mСтандартное отклонение продолжительности поездок: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_dev_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m минут\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Timedelta.__format__"
     ]
    }
   ],
   "source": [
    "print(f\"\\nСтандартное отклонение продолжительности поездок: {std_dev_duration:.2f} минут\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78f30111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1554026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84450ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_minutes'] = df['duration'].dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "662d9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev_duration_calculated = df['duration_minutes'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38af6b9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Timedelta.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mСтандартное отклонение продолжительности поездок: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_dev_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m минут\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Timedelta.__format__"
     ]
    }
   ],
   "source": [
    "print(f\"\\nСтандартное отклонение продолжительности поездок: {std_dev_duration:.2f} минут\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be6f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame успешно загружен из parquet файла.\n",
      "\n",
      "Столбцы дат успешно преобразованы в datetime.\n",
      "\n",
      "Столбец 'duration' создан. Тип данных: timedelta64[ns]\n",
      "\n",
      "Столбец 'duration_minutes' успешно создан. Тип данных: float64\n",
      "\n",
      "DataFrame с вычисленной продолжительностью поездки (первые 5 строк):\n",
      "  tpep_pickup_datetime tpep_dropoff_datetime  duration_minutes\n",
      "0  2023-01-01 00:32:10   2023-01-01 00:40:36          8.433333\n",
      "1  2023-01-01 00:55:08   2023-01-01 01:01:27          6.316667\n",
      "2  2023-01-01 00:25:04   2023-01-01 00:37:49         12.750000\n",
      "3  2023-01-01 00:03:48   2023-01-01 00:13:25          9.616667\n",
      "4  2023-01-01 00:10:29   2023-01-01 00:21:19         10.833333\n",
      "--------------------------------------------------\n",
      "\n",
      "Тип вычисленного std_dev_duration: <class 'float'>\n",
      "Стандартное отклонение продолжительности поездок в январе: 42.59 минут\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Загрузка данных (замените на ваш реальный файл, если используете его)\n",
    "try:\n",
    "    df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "    print(\"DataFrame успешно загружен из parquet файла.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Файл 'yellow_tripdata_2023-01.parquet' не найден. Использую пример данных.\")\n",
    "    data = {\n",
    "        'VendorID': [2, 2, 2, 1, 2],\n",
    "        'tpep_pickup_datetime': ['2023-01-01 00:32:10', '2023-01-01 00:55:08', '2023-01-01 00:25:04', '2023-01-01 00:03:48', '2023-01-01 00:10:29'],\n",
    "        'tpep_dropoff_datetime': ['2023-01-01 00:40:36', '2023-01-01 01:01:27', '2023-01-01 00:37:49', '2023-01-01 00:13:25', '2023-01-01 00:21:19'],\n",
    "        'passenger_count': [1.0, 1.0, 1.0, 0.0, 1.0],'trip_distance': [0.97, 1.10, 2.51, 1.90, 1.43],'RatecodeID': [1.0, 1.0, 1.0, 1.0, 1.0],'store_and_fwd_flag': ['N', 'N', 'N', 'N', 'N'],'PULocationID': [161, 43, 48, 138, 107],'DOLocationID': [141, 237, 238, 7, 79],'payment_type': [2, 1, 1, 1, 1],'fare_amount': [9.3, 7.9, 14.9, 12.1, 11.4],'extra': [1.00, 1.00, 1.00, 7.25, 1.00],'mta_tax': [0.5, 0.5, 0.5, 0.5, 0.5],'tip_amount': [0.00, 4.00, 15.00, 0.00, 3.28],'tolls_amount': [0.0, 0.0, 0.0, 0.0, 0.0],'improvement_surcharge': [1.0, 1.0, 1.0, 1.0, 1.0],'total_amount': [14.30, 16.90, 34.90, 20.85, 19.68],'congestion_surcharge': [2.5, 2.5, 2.5, 0.0, 2.5],'airport_fee': [0.00, 0.00, 0.00, 1.25, 0.00]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Создан пример DataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка при загрузке данных: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Преобразование столбцов с датой и временем в формат datetime\n",
    "try:\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    print(\"\\nСтолбцы дат успешно преобразованы в datetime.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nОшибка при преобразовании столбцов дат: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 3. Вычисление продолжительности поездки (как Timedelta)\n",
    "try:\n",
    "    df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "    print(f\"\\nСтолбец 'duration' создан. Тип данных: {df['duration'].dtype}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nОшибка при вычислении столбца 'duration': {e}\")\n",
    "    exit()\n",
    "\n",
    "# 4. Преобразование продолжительности в минуты (как float)\n",
    "try:\n",
    "    if pd.api.types.is_timedelta64_dtype(df['duration']):\n",
    "        df['duration_minutes'] = df['duration'].dt.total_seconds() / 60\n",
    "        print(f\"\\nСтолбец 'duration_minutes' успешно создан. Тип данных: {df['duration_minutes'].dtype}\")\n",
    "        # Проверим, что это действительно float\n",
    "        if df['duration_minutes'].dtype != 'float64' and df['duration_minutes'].dtype != 'float32':\n",
    "            print(f\"ПРЕДУПРЕЖДЕНИЕ: 'duration_minutes' не является float, а {df['duration_minutes'].dtype}. Это может вызвать проблемы.\")\n",
    "    else:\n",
    "        print(f\"\\nОшибка: столбец 'duration' не является Timedelta (тип: {df['duration'].dtype}). Невозможно вычислить 'duration_minutes'.\")\n",
    "        exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\nОшибка при вычислении столбца 'duration_minutes': {e}\")\n",
    "    exit()\n",
    "\n",
    "# Выведем первые несколько строк с новой колонкой для проверки\n",
    "print(\"\\nDataFrame с вычисленной продолжительностью поездки (первые 5 строк):\")\n",
    "if 'duration_minutes' in df.columns:\n",
    "    print(df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration_minutes']].head())\n",
    "else:\n",
    "    print(\"ОШИБКА: Столбец 'duration_minutes' отсутствует в DataFrame!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 5. Вычисление стандартного отклонения продолжительности поездок в минутах\n",
    "std_dev_duration = None # Инициализируем\n",
    "if 'duration_minutes' in df.columns:\n",
    "    # Убедимся, что duration_minutes - числовой столбец\n",
    "    if pd.api.types.is_numeric_dtype(df['duration_minutes']):\n",
    "        std_dev_duration = df['duration_minutes'].std() # Это должно вернуть float\n",
    "        print(f\"\\nТип вычисленного std_dev_duration: {type(std_dev_duration)}\")\n",
    "        # Теперь печатаем\n",
    "        if isinstance(std_dev_duration, float):\n",
    "             print(f\"Стандартное отклонение продолжительности поездок в январе: {std_dev_duration:.2f} минут\")\n",
    "        else:\n",
    "            # Этого не должно произойти, если df['duration_minutes'] числовой\n",
    "            print(f\"std_dev_duration не float ({type(std_dev_duration)}), преобразуем для вывода...\")\n",
    "            if isinstance(std_dev_duration, pd.Timedelta): # На всякий случай\n",
    "                 std_dev_duration_numeric_minutes = std_dev_duration.total_seconds() / 60\n",
    "                 print(f\"Стандартное отклонение продолжительности поездок в январе: {std_dev_duration_numeric_minutes:.2f} минут\")\n",
    "            else:\n",
    "                 print(f\"Не удалось отформатировать std_dev_duration: {std_dev_duration}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nСтолбец 'duration_minutes' не является числовым (тип: {df['duration_minutes'].dtype}). Невозможно рассчитать стандартное отклонение корректно.\")\n",
    "        # Если бы мы все равно хотели std от Timedelta (но это не то, что нам нужно для числового ответа)\n",
    "        # std_dev_timedelta = df['duration'].std()\n",
    "        # print(f\"Стандартное отклонение (как Timedelta) от df['duration']: {std_dev_timedelta}\")\n",
    "        # std_dev_duration_numeric_minutes = std_dev_timedelta.total_seconds() / 60\n",
    "        # print(f\"Это значение в минутах: {std_dev_duration_numeric_minutes:.2f} минут\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nНевозможно рассчитать стандартное отклонение, так как столбец 'duration_minutes' отсутствует.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbd6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное количество записей: 3066766\n",
      "Количество записей после фильтрации (1-60 мин): 3009173\n",
      "\n",
      "Доля оставшихся записей после удаления выбросов: 0.9812 (или 98.12%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Предполагается, что предыдущий код уже выполнен ---\n",
    "# Например, загрузка данных и вычисление duration_minutes:\n",
    "#\n",
    "# try:\n",
    "#     df = pd.read_parquet('yellow_tripdata_2023-01.parquet')\n",
    "# except FileNotFoundError:\n",
    "#     print(\"Файл не найден, используется пример DataFrame\")\n",
    "#     data = {\n",
    "#         'tpep_pickup_datetime': ['2023-01-01 00:32:10', '2023-01-01 00:55:08', '2023-01-01 00:25:04', '2023-01-01 00:03:48', '2023-01-01 00:10:29', '2023-01-01 00:00:00', '2023-01-01 01:30:00'],\n",
    "#         'tpep_dropoff_datetime': ['2023-01-01 00:40:36', '2023-01-01 01:01:27', '2023-01-01 00:37:49', '2023-01-01 00:13:25', '2023-01-01 00:21:19', '2023-01-01 00:00:30', '2023-01-01 01:35:00']\n",
    "#     } # Добавлены значения для демонстрации фильтрации\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "# df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "# df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "# df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "# df['duration_minutes'] = df['duration'].dt.total_seconds() / 60\n",
    "#\n",
    "# print(\"Исходный DataFrame (пример с duration_minutes):\")\n",
    "# print(df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'duration_minutes']].head(7))\n",
    "# print(\"-\" * 50)\n",
    "# --- Конец предполагаемого предыдущего кода ---\n",
    "\n",
    "\n",
    "# Проверяем, существует ли столбец 'duration_minutes'\n",
    "if 'duration_minutes' not in df.columns:\n",
    "    print(\"Ошибка: Столбец 'duration_minutes' не найден. Пожалуйста, убедитесь, что он был вычислен корректно.\")\n",
    "    # Здесь можно добавить код для вычисления, если он отсутствует, или прервать выполнение\n",
    "    # exit()\n",
    "else:\n",
    "    print(f\"Исходное количество записей: {len(df)}\")\n",
    "\n",
    "    # 1. Фильтрация данных: оставляем только записи, где продолжительность от 1 до 60 минут включительно.\n",
    "    # Создаем условия\n",
    "    condition_lower_bound = df['duration_minutes'] >= 1\n",
    "    condition_upper_bound = df['duration_minutes'] <= 60\n",
    "\n",
    "    # Применяем оба условия (логическое \"И\" - &)\n",
    "    df_filtered = df[condition_lower_bound & condition_upper_bound].copy() # Используем .copy() для избежания SettingWithCopyWarning\n",
    "\n",
    "    # Вы можете также перезаписать исходный DataFrame, если он больше не нужен в первоначальном виде:\n",
    "    # df = df[condition_lower_bound & condition_upper_bound].copy()\n",
    "    # num_records_after_filtering = len(df)\n",
    "\n",
    "    num_records_after_filtering = len(df_filtered)\n",
    "    print(f\"Количество записей после фильтрации (1-60 мин): {num_records_after_filtering}\")\n",
    "\n",
    "    # 2. Вычисление доли оставшихся записей\n",
    "    original_num_records = len(df) # Используем len(df) до фильтрации, если не перезаписывали df\n",
    "\n",
    "    if original_num_records > 0:\n",
    "        fraction_left = num_records_after_filtering / original_num_records\n",
    "        print(f\"\\nДоля оставшихся записей после удаления выбросов: {fraction_left:.4f} (или {fraction_left*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"\\nИсходный DataFrame был пуст, невозможно рассчитать долю.\")\n",
    "\n",
    "    # Для дальнейших заданий вы, вероятно, захотите работать с отфильтрованным DataFrame\n",
    "    # Если вы создали df_filtered, не забудьте использовать его в следующих шагах.\n",
    "    # Или, если вы перезаписали df, просто продолжайте работать с df.\n",
    "    # Например, для следующих шагов:\n",
    "    # df_for_next_step = df_filtered\n",
    "    # print(\"\\nПервые 5 строк отфильтрованного DataFrame:\")\n",
    "    # print(df_for_next_step.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d56d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame с ID, преобразованными в строки (первые 5 строк):\n",
      "  PULocationID DOLocationID\n",
      "0          161          141\n",
      "1           43          237\n",
      "2           48          238\n",
      "3          138            7\n",
      "4          107           79\n",
      "--------------------------------------------------\n",
      "\n",
      "Первый словарь в списке:\n",
      "{'PULocationID': '161', 'DOLocationID': '141'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Тип полученной матрицы признаков: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Размерность матрицы признаков (строки, столбцы): (3009173, 515)\n",
      "--------------------------------------------------\n",
      "Размерность (количество столбцов) полученной матрицы признаков: 515\n",
      "\n",
      "Количество уникальных строковых PULocationID: 255\n",
      "Количество уникальных строковых DOLocationID: 260\n",
      "Ожидаемая размерность (сумма уникальных PU и DO ID): 515\n",
      "(Примечание: если одно и то же ID используется и как PU, и как DO, оно будет закодировано дважды, например, PULocationID=X и DOLocationID=X)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# --- Предполагается, что предыдущий код уже выполнен ---\n",
    "# Например, у вас есть df_filtered\n",
    "# Для примера, создадим небольшой df_filtered, если он не существует\n",
    "if 'df_filtered' not in locals():\n",
    "    print(\"df_filtered не найден, создаю пример...\")\n",
    "    data_example = {\n",
    "        'PULocationID': [161, 43, 48, 138, 107, 161, 43, 200], # Добавим несколько значений\n",
    "        'DOLocationID': [141, 237, 238, 7, 79, 141, 100, 200], # Добавим несколько значений, включая совпадающее с PU\n",
    "        'duration_minutes': [8.43, 6.31, 12.75, 9.61, 10.83, 7.0, 15.0, 30.0],\n",
    "        'VendorID': [1,2,1,2,1,1,2,1] # Другие колонки, которые не будут использоваться\n",
    "    }\n",
    "    df_filtered = pd.DataFrame(data_example)\n",
    "    print(\"Пример df_filtered создан:\")\n",
    "    print(df_filtered.head())\n",
    "    print(\"-\" * 50)\n",
    "# --- Конец предполагаемого предыдущего кода ---\n",
    "\n",
    "# 1. Выбор нужных признаков\n",
    "features_to_encode = ['PULocationID', 'DOLocationID']\n",
    "df_subset = df_filtered[features_to_encode].copy() # .copy() чтобы избежать SettingWithCopyWarning\n",
    "\n",
    "# 2. Преобразование ID в строки\n",
    "# Это важно, чтобы DictVectorizer рассматривал их как категориальные метки\n",
    "df_subset['PULocationID'] = df_subset['PULocationID'].astype(str)\n",
    "df_subset['DOLocationID'] = df_subset['DOLocationID'].astype(str)\n",
    "\n",
    "print(\"\\nDataFrame с ID, преобразованными в строки (первые 5 строк):\")\n",
    "print(df_subset.head())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Преобразование DataFrame в список словарей\n",
    "# Каждая строка становится словарем, где ключи - это имена столбцов\n",
    "list_of_dicts = df_subset.to_dict(orient='records')\n",
    "\n",
    "# Посмотрим на первый элемент списка для примера\n",
    "if list_of_dicts:\n",
    "    print(\"\\nПервый словарь в списке:\")\n",
    "    print(list_of_dicts[0])\n",
    "else:\n",
    "    print(\"\\nСписок словарей пуст (возможно, df_filtered был пуст).\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Инициализация и обучение DictVectorizer\n",
    "dv = DictVectorizer() # sparse=True по умолчанию, что обычно хорошо для высокой размерности\n",
    "dv.fit(list_of_dicts)\n",
    "\n",
    "# Посмотрим на некоторые из выученных имен признаков (если их не слишком много)\n",
    "# feature_names = dv.get_feature_names_out()\n",
    "# print(\"\\nНекоторые из имен признаков, созданных DictVectorizer:\")\n",
    "# print(feature_names[:10]) # Показываем первые 10\n",
    "# print(f\"... и еще {len(feature_names) - 10 if len(feature_names) > 10 else 0} признаков.\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 5. Получение матрицы признаков\n",
    "# .transform() возвращает разреженную матрицу (sparse matrix) по умолчанию\n",
    "feature_matrix = dv.transform(list_of_dicts)\n",
    "\n",
    "print(\"\\nТип полученной матрицы признаков:\", type(feature_matrix))\n",
    "print(\"Размерность матрицы признаков (строки, столбцы):\", feature_matrix.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 6. Определение размерности (количества столбцов)\n",
    "dimensionality = feature_matrix.shape[1]\n",
    "print(f\"Размерность (количество столбцов) полученной матрицы признаков: {dimensionality}\")\n",
    "\n",
    "# Дополнительно: как это число получается?\n",
    "# Это сумма уникальных значений 'PULocationID=...' и 'DOLocationID=...'\n",
    "# Уникальные значения PULocationID (как строки)\n",
    "unique_pu = df_subset['PULocationID'].nunique()\n",
    "# Уникальные значения DOLocationID (как строки)\n",
    "unique_do = df_subset['DOLocationID'].nunique()\n",
    "\n",
    "print(f\"\\nКоличество уникальных строковых PULocationID: {unique_pu}\")\n",
    "print(f\"Количество уникальных строковых DOLocationID: {unique_do}\")\n",
    "print(f\"Ожидаемая размерность (сумма уникальных PU и DO ID): {unique_pu + unique_do}\")\n",
    "print(\"(Примечание: если одно и то же ID используется и как PU, и как DO, оно будет закодировано дважды, например, PULocationID=X и DOLocationID=X)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50c7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель линейной регрессии обучена.\n",
      "--------------------------------------------------\n",
      "RMSE на обучающих данных: 7.65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer # Было использовано ранее\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np # для np.sqrt\n",
    "\n",
    "# --- Предполагается, что предыдущий код уже выполнен ---\n",
    "# У вас должны быть:\n",
    "# 1. df_filtered: DataFrame после фильтрации по продолжительности (1-60 мин)\n",
    "# 2. feature_matrix: Матрица признаков (X_train) после DictVectorizer\n",
    "# 3. dv: Обученный DictVectorizer (хотя он нам здесь напрямую не нужен, но он создавал feature_matrix)\n",
    "\n",
    "# Для примера, если переменные не существуют, создадим их (упрощенно)\n",
    "if 'df_filtered' not in locals() or 'feature_matrix' not in locals():\n",
    "    print(\"df_filtered или feature_matrix не найдены, создаю пример...\")\n",
    "    # Пример df_filtered (нужен для y_train)\n",
    "    data_example_filtered = {\n",
    "        'PULocationID': [161, 43, 48, 138, 107, 200],\n",
    "        'DOLocationID': [141, 237, 238, 7, 79, 100],\n",
    "        'duration_minutes': [8.43, 6.31, 12.75, 9.61, 10.83, 15.0] # Наш y\n",
    "    }\n",
    "    df_filtered = pd.DataFrame(data_example_filtered)\n",
    "\n",
    "    # Пример feature_matrix (X_train)\n",
    "    # В реальном коде это результат dv.transform()\n",
    "    temp_dicts = df_filtered[['PULocationID', 'DOLocationID']].astype(str).to_dict(orient='records')\n",
    "    dv_example = DictVectorizer()\n",
    "    feature_matrix = dv_example.fit_transform(temp_dicts) # Это будет X_train\n",
    "    print(\"Примерные df_filtered и feature_matrix созданы.\")\n",
    "    print(f\"Размер df_filtered: {df_filtered.shape}\")\n",
    "    print(f\"Размер feature_matrix: {feature_matrix.shape}\")\n",
    "    print(\"-\" * 50)\n",
    "# --- Конец предполагаемого предыдущего кода ---\n",
    "\n",
    "\n",
    "# 1. Подготовка целевой переменной (y_train)\n",
    "# Убедимся, что 'duration_minutes' существует в df_filtered\n",
    "if 'duration_minutes' not in df_filtered.columns:\n",
    "    raise ValueError(\"Столбец 'duration_minutes' отсутствует в df_filtered. Пожалуйста, убедитесь, что он был создан.\")\n",
    "\n",
    "y_train = df_filtered['duration_minutes'].values\n",
    "# .values преобразует Pandas Series в NumPy array, что часто предпочитают модели scikit-learn.\n",
    "\n",
    "# Проверка соответствия размеров X_train и y_train\n",
    "if feature_matrix.shape[0] != len(y_train):\n",
    "    raise ValueError(f\"Несоответствие количества строк! feature_matrix: {feature_matrix.shape[0]}, y_train: {len(y_train)}\")\n",
    "\n",
    "# 2. Инициализация и обучение модели линейной регрессии\n",
    "# \"plain linear regression model with default parameters\"\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(feature_matrix, y_train)\n",
    "\n",
    "print(\"\\nМодель линейной регрессии обучена.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Получение предсказаний на обучающих данных\n",
    "y_pred_train = lr_model.predict(feature_matrix)\n",
    "\n",
    "# 4. Расчет RMSE (Root Mean Squared Error) на обучающих данных\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train = np.sqrt(mse_train) # или mse_train**0.5\n",
    "\n",
    "print(f\"RMSE на обучающих данных: {rmse_train:.2f}\") # Округляем до 2 знаков после запятой для типичного ответа\n",
    "\n",
    "# Если нужно посмотреть на несколько предсказаний и реальных значений:\n",
    "# print(\"\\nПример реальных и предсказанных значений на обучающих данных:\")\n",
    "# for i in range(min(5, len(y_train))): # Показываем до 5 примеров\n",
    "#     print(f\"Реальное: {y_train[i]:.2f}, Предсказанное: {y_pred_train[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba226c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Загрузка валидационных данных из: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Валидационные данные загружены. Количество строк: 2913955\n",
      "Количество записей в валидационном наборе до фильтрации: 2913955\n",
      "Количество записей в валидационном наборе после фильтрации (1-60 мин): 2855951\n",
      "--------------------------------------------------\n",
      "\n",
      "Валидационные данные преобразованы с использованием обученного DictVectorizer.\n",
      "Размерность X_val (строки, столбцы): (2855951, 515)\n",
      "--------------------------------------------------\n",
      "RMSE на валидационных данных (февраль 2023): 7.81\n",
      "Для сравнения, RMSE на обучающих данных был: 7.65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer # Was used for training\n",
    "from sklearn.linear_model import LinearRegression    # The trained model type\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Предполагается, что у вас есть обученные 'dv' и 'lr_model' из предыдущих шагов ---\n",
    "# Если их нет, вы не сможете выполнить этот шаг корректно.\n",
    "# Для примера, если переменные не существуют, создадим их (упрощенно)\n",
    "if 'dv' not in locals() or 'lr_model' not in locals():\n",
    "    print(\"Обученные 'dv' и 'lr_model' не найдены. Этот скрипт не сможет работать корректно без них.\")\n",
    "    print(\"Пожалуйста, убедитесь, что вы сначала выполнили скрипты обучения.\")\n",
    "    # Для продолжения демонстрации создадим \"пустышки\"\n",
    "    # В реальном сценарии здесь нужно было бы прервать выполнение или загрузить сохраненные модели\n",
    "    class DummyDV:\n",
    "        def transform(self, X):\n",
    "            # Простейшая реализация для примера, которая может не сработать с реальными данными\n",
    "            from scipy.sparse import csr_matrix\n",
    "            if not X: return csr_matrix((0,0))\n",
    "            num_samples = len(X)\n",
    "            # Пытаемся угадать количество признаков из первого элемента, если он есть\n",
    "            num_features = len(X[0]) if X else 0 # Это ОЧЕНЬ грубое предположение\n",
    "            return csr_matrix((num_samples, num_features)) # Возвращает пустую разреженную матрицу нужного размера\n",
    "        def get_feature_names_out(self): return []\n",
    "\n",
    "    class DummyLR:\n",
    "        def predict(self, X):\n",
    "            return np.zeros(X.shape[0]) # Всегда предсказывает 0\n",
    "\n",
    "    dv = DummyDV()\n",
    "    lr_model = DummyLR()\n",
    "    print(\"Созданы 'пустышки' для 'dv' и 'lr_model' для демонстрации. Результаты будут некорректными.\")\n",
    "    print(\"-\" * 50)\n",
    "# --- Конец секции с проверкой наличия моделей ---\n",
    "\n",
    "\n",
    "# 1. Загрузка данных валидации (февраль 2023)\n",
    "validation_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "try:\n",
    "    print(f\"\\nЗагрузка валидационных данных из: {validation_data_url}\")\n",
    "    df_val = pd.read_parquet(validation_data_url)\n",
    "    print(f\"Валидационные данные загружены. Количество строк: {len(df_val)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при загрузке валидационных данных: {e}\")\n",
    "    exit() # Прерываем выполнение, если данные не загружены\n",
    "\n",
    "# 2. Предобработка валидационных данных (аналогично обучающим)\n",
    "\n",
    "# 2a. Преобразование столбцов дат и вычисление продолжительности\n",
    "df_val['tpep_pickup_datetime'] = pd.to_datetime(df_val['tpep_pickup_datetime'])\n",
    "df_val['tpep_dropoff_datetime'] = pd.to_datetime(df_val['tpep_dropoff_datetime'])\n",
    "df_val['duration'] = df_val['tpep_dropoff_datetime'] - df_val['tpep_pickup_datetime']\n",
    "df_val['duration_minutes'] = df_val['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# 2b. Фильтрация по продолжительности\n",
    "original_val_records = len(df_val)\n",
    "condition_lower_val = df_val['duration_minutes'] >= 1\n",
    "condition_upper_val = df_val['duration_minutes'] <= 60\n",
    "df_val_filtered = df_val[condition_lower_val & condition_upper_val].copy()\n",
    "\n",
    "if len(df_val_filtered) == 0:\n",
    "    print(\"После фильтрации в валидационном наборе не осталось данных. RMSE не может быть вычислен.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Количество записей в валидационном наборе до фильтрации: {original_val_records}\")\n",
    "print(f\"Количество записей в валидационном наборе после фильтрации (1-60 мин): {len(df_val_filtered)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2c. Выбор признаков и преобразование ID в строки\n",
    "features_to_encode_val = ['PULocationID', 'DOLocationID']\n",
    "df_val_subset = df_val_filtered[features_to_encode_val].copy()\n",
    "df_val_subset['PULocationID'] = df_val_subset['PULocationID'].astype(str)\n",
    "df_val_subset['DOLocationID'] = df_val_subset['DOLocationID'].astype(str)\n",
    "\n",
    "# 3. Преобразование DataFrame валидации в список словарей\n",
    "val_list_of_dicts = df_val_subset.to_dict(orient='records')\n",
    "\n",
    "# 4. Применение ОБУЧЕННОГО DictVectorizer к валидационным данным\n",
    "# ВАЖНО: используем .transform(), а не .fit() или .fit_transform()\n",
    "# `dv` должен быть тем же самым объектом, который был обучен на тренировочных данных.\n",
    "X_val = dv.transform(val_list_of_dicts)\n",
    "\n",
    "print(\"\\nВалидационные данные преобразованы с использованием обученного DictVectorizer.\")\n",
    "print(\"Размерность X_val (строки, столбцы):\", X_val.shape)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 5. Подготовка целевой переменной для валидации (y_val)\n",
    "y_val = df_val_filtered['duration_minutes'].values\n",
    "\n",
    "# Проверка соответствия размеров X_val и y_val\n",
    "if X_val.shape[0] != len(y_val):\n",
    "    raise ValueError(f\"Несоответствие количества строк! X_val: {X_val.shape[0]}, y_val: {len(y_val)}\")\n",
    "\n",
    "\n",
    "# 6. Получение предсказаний на валидационных данных с помощью ОБУЧЕННОЙ модели\n",
    "# `lr_model` должен быть тем же самым объектом, который был обучен на тренировочных данных.\n",
    "y_pred_val = lr_model.predict(X_val)\n",
    "\n",
    "# 7. Расчет RMSE на валидационных данных\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "\n",
    "print(f\"RMSE на валидационных данных (февраль 2023): {rmse_val:.2f}\")\n",
    "\n",
    "# Сравнение с RMSE на обучающих данных (если переменная rmse_train существует из предыдущего шага)\n",
    "if 'rmse_train' in locals():\n",
    "    print(f\"Для сравнения, RMSE на обучающих данных был: {rmse_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50294e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
